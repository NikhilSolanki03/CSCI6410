---
output:
  html_document: default
  pdf_document: default
---
```{r setup}
knitr::opts_chunk$set(echo = TRUE)
library(readr)
library(dplyr)
library(tidyr)
library(ggplot2)
library(scales)
library(tidytext)
library(textstem)
library(clinspacy)
library(topicmodels)
library('reshape2')
library(stringr)

```




```{r}
raw.data <- clinspacy::dataset_mtsamples()
dplyr::glimpse(raw.data)
View(raw.data)
```

  

**1** Using the output of dplyr's `glimpse` command (or rstudio's data viewer by clicking on `raw.data` in the Environment pane) provide a description of what you think each variable in this dataset contains.

Answer:
-note_id: A unique numeric identifier for each transcription note.

-description: A brief summary of the clinical case or visit (e.g., patient complaints).

-medical_specialty: The department or domain that authored the note (e.g., Radiology, Surgery).

-sample_name: The name of the medical report or procedure type (e.g., "Laparoscopic Gastric Bypass").

-transcription: The full free-text clinical note or medical transcription for a patient visit.

-keywords: A comma-separated list of relevant clinical keywords/tags extracted from the note.



```{r}

raw.data %>% dplyr::select(medical_specialty) %>% dplyr::n_distinct()
```




```{r}
ggplot2::ggplot(raw.data, ggplot2::aes(y=medical_specialty)) + ggplot2::geom_bar() + labs(x="Document Count", y="Medical Speciality")
```



```{r} 
filtered.data <- raw.data %>% dplyr::filter(medical_specialty %in% c("Orthopedic", "Radiology", "Surgery")) 
```



```{r}

analysis.data <- filtered.data %>%
  unnest_tokens(word, transcription) %>%
  mutate(word = str_replace_all(word, "[^[:alnum:]]", "")) %>%
  filter(!str_detect(word, "[0-9]")) %>%
  anti_join(stop_words) %>%
  group_by(note_id) %>%
  summarise(transcription = paste(word, collapse = " ")) %>%
  left_join(select(filtered.data, -transcription), by = "note_id")
```




```{r}
tokenized.data.unigram <- analysis.data %>% tidytext::unnest_tokens(word, transcription, to_lower=TRUE)
```


```{r}
tokenized.data <- analysis.data %>% tidytext::unnest_tokens(ngram, transcription, token = "ngrams", n=2, to_lower = TRUE)
```


```{r}
tidytext::stop_words %>% dplyr::group_by(lexicon) %>% dplyr::distinct(word) %>% dplyr::summarise(n=dplyr::n())
```

**2** How many unique unigrams are there in the transcripts from each specialty:

Answer:-

```{r}
tokenized.data.unigram %>%
  group_by(medical_specialty) %>%
  summarise(unique_unigrams = n_distinct(word))



```

The unique unigrams are as followed:
Orthopedic - 7681
Radiology - 5933
Surgery - 11977





```{r}
word_counts <- tokenized.data.unigram %>%
    group_by(word) %>%
    summarise(count = n()) %>%
    ungroup() %>%
    arrange(desc(count))

count_distribution <- word_counts %>%
  group_by(count) %>%
  summarise(num_words = n()) %>%
  ungroup()
 
 ggplot2::ggplot(count_distribution, aes(x = count, y = num_words)) +
  geom_point() +
  labs(title = "Scatter Plot of Count Distribution",
       x = "Count of Unique Words",
       y = "Number of Words")
```





```{r}
word_counts <- tokenized.data %>%
    group_by(ngram) %>%
    summarise(count = n()) %>%
    ungroup() %>%
    arrange(desc(count))

count_distribution <- word_counts %>%
  group_by(count) %>%
  summarise(num_words = n()) %>%
  ungroup()
 
 ggplot2::ggplot(count_distribution, aes(x = count, y = num_words)) +
  geom_point() +
  labs(title = "Scatter Plot of Count Distribution",
       x = "Count of Unique Bigrams",
       y = "Number of Words")
```

**3** How many unique bi-grams are there in each category without stop words and numbers?

Answer:-

```{r}
tokenized.data %>%
  group_by(medical_specialty) %>%
  summarise(unique_bigrams = n_distinct(ngram))

```
The unique bigrams are as followed:
Orthopedic - 55730
Radiology - 28294
Surgery - 130404




**4** How many unique sentences are there in each category? Hint: use `?tidytext::unnest_tokens` to see the documentation for this function.

Answer:-

```{r}
sentence_data <- analysis.data %>%
  unnest_tokens(sentence, transcription, token = "sentences")

sentence_data %>%
  group_by(medical_specialty) %>%
  summarise(unique_sentences = n_distinct(sentence))


```
The unique sentences are as followed:
Orthopedic - 354
Radiology - 273
Surgery - 1087



```{r}
tokenized.data %>%
  dplyr::group_by(medical_specialty) %>%
  dplyr::count(ngram, sort = TRUE) %>%
  dplyr::top_n(5)
```



**5** Do you think a general purpose lemmatizer will work well for medical data? Why might it not?
Answer:-

-A general-purpose lemmatizer (such as the one included in tidytext, textstem, or even spaCy's base model) may not work optimally for medical data because:

  1-Lack of Medical Vocabulary:

General lemmatizers are trained on generic corpora (like news, Wikipedia), so they often do not recognize domain-specific terms such as:

              -“hemoptysis” → might remain unchanged or incorrectly lemmatized.

              -“angioplasties” → might not reduce to “angioplasty”.

  2-Abbreviations and Jargon:

Medical notes contain abbreviations (e.g., “BP”, “MI”, “HTN”) that general lemmatizers don’t handle or expand, leading to loss of meaning.

  3-Multi-word Terms:

Medical concepts often appear as multi-word expressions (e.g., “range of motion”, “chest x-ray”), which general lemmatizers break into individual words, disrupting context.

  4-Incorrect Part-of-Speech Tagging:

Clinical sentences are often unstructured, contain typos, or use non-standard grammar, making it hard for general-purpose lemmatizers to assign correct POS tags—which is essential for accurate lemmatization.



```{r}
lemmatized.data <- tokenized.data %>% dplyr::mutate(lemma=textstem::lemmatize_words(ngram))
```


```{r}
lemma.freq <- lemmatized.data %>% 
  dplyr::count(medical_specialty, lemma) %>%
  dplyr::group_by(medical_specialty) %>% 
  dplyr::mutate(proportion = n / sum(n)) %>%
  tidyr::pivot_wider(names_from = medical_specialty, values_from = proportion) %>%
  tidyr::pivot_longer(`Surgery`:`Radiology`,
               names_to = "medical_specialty", values_to = "proportion")
```


```{r}

ggplot2::ggplot(lemma.freq, ggplot2::aes(x= proportion, 
                                         y=`Orthopedic`,
                                         color=abs(`Orthopedic` - proportion))) + 
  ggplot2::geom_abline(color="gray40", lty=2) +
  ggplot2::geom_jitter(alpha=0.1, size=2.5, width=0.3, height=0.3) +
  ggplot2::geom_text(ggplot2::aes(label=lemma), check_overlap=TRUE, vjust=1.5) +
  ggplot2::scale_x_log10(labels=scales::percent_format()) + 
  ggplot2::scale_y_log10(labels=scales::percent_format()) + 
  ggplot2::scale_color_gradient(limits=c(0, 0.001), low="darkslategray4", high="gray75") +
  ggplot2::facet_wrap(~medical_specialty, ncol = 2) +
  ggplot2::theme(legend.position="none") +
  ggplot2:: labs(y="Orthopedic", x = NULL)
```
**6** What does this plot tell you about the relative similarity of lemma frequencies between Surgery and Orthopedic and between radiology and Surgery? Based on what these specialties involve, is this what you would expect?

Answer:-

This plot suggests that lemma frequencies between Surgery and Orthopedic are more similar than those between Radiology and Surgery. In the Surgery panel, many lemmas cluster closer to the diagonal dashed line, indicating a higher overlap with Orthopedic terminology. Meanwhile, the Radiology panel shows more differentiation, with many lemmas appearing farther from the diagonal.
This pattern makes sense given the nature of these specialties. Surgery and Orthopedic both involve direct physical interventions on bones, ligaments, and muscles, which naturally leads to shared terminology. Radiology, on the other hand, focuses more on imaging and diagnostics rather than surgical procedures, resulting in a distinct vocabulary.



**7** Modify the above plotting code to do a direct comparison of Surgery and Radiology (i.e., have Surgery or Radiology on the Y-axis and the other 2 specialties as the X facets)

Answer:-

```{r}
lemma.freq2 <- lemmatized.data %>% 
  dplyr::count(medical_specialty, lemma) %>%
  dplyr::group_by(medical_specialty) %>% 
  dplyr::mutate(proportion = n / sum(n)) %>%
  tidyr::pivot_wider(names_from = medical_specialty, values_from = proportion) %>%
  tidyr::pivot_longer(`Orthopedic`:`Radiology`,
               names_to = "medical_specialty", values_to = "proportion")




ggplot2::ggplot(lemma.freq2, ggplot2::aes(x= `proportion`, 
                                         y=`Surgery`,
                                         color=abs(`Surgery` - proportion))) + 
  ggplot2::geom_abline(color="gray40", lty=2) +
  ggplot2::geom_jitter(alpha=0.1, size=2.5, width=0.3, height=0.3) +
  ggplot2::geom_text(ggplot2::aes(label=lemma), check_overlap=TRUE, vjust=1.5) +
  ggplot2::scale_x_log10(labels=scales::percent_format()) + 
  ggplot2::scale_y_log10(labels=scales::percent_format()) + 
  ggplot2::scale_color_gradient(limits=c(0, 0.001), low="darkslategray4", high="gray75") +
  ggplot2::facet_wrap(~medical_specialty, ncol = 2) +
  ggplot2::theme(legend.position="none") +
  ggplot2:: labs(y="Surgery", x = NULL)

```






```{r}
lemma.counts <- lemmatized.data %>% dplyr::count(medical_specialty, lemma)
total.counts <- lemma.counts %>% 
                      dplyr::group_by(medical_specialty) %>% 
                      dplyr::summarise(total=sum(n))

all.counts <- dplyr::left_join(lemma.counts, total.counts)
```


```{r}
all.counts.tfidf <- tidytext::bind_tf_idf(all.counts, lemma, medical_specialty, n) 
```



```{r}
all.counts.tfidf %>% dplyr::group_by(medical_specialty) %>% dplyr::slice_max(order_by=tf_idf, n=10)


```
**8** Are there any lemmas that stand out in these lists? Why or why not?

Answer:-
Yes, a few lemmas do stand out! Specifically, terms like "range motion" (Orthopedic), "myocardial perfusion" (Radiology), and "anterior chamber" (Surgery) are particularly notable. Here's why:
- "Range motion" (Orthopedic) – This term is central to orthopedic evaluations, as assessing joint flexibility and mobility is a key aspect of diagnosing musculoskeletal conditions.
- "Myocardial perfusion" (Radiology) – This lemma relates to a critical imaging study used to evaluate blood flow in the heart muscle. It's a crucial term in radiology, especially in detecting coronary artery disease.
- "Anterior chamber" (Surgery) – This term is important in ophthalmologic and surgical contexts, referring to the fluid-filled space between the cornea and iris. Procedures involving the anterior chamber are essential in eye surgeries like cataract removal.
These lemmas stand out because they directly relate to specialized diagnostic or procedural terms that are fundamental within their respective fields. Other lemmas, like "closed vicryl" (Surgery) and "dissection carried" (Orthopedic), are also interesting because they represent common surgical techniques.





```{r}
analysis.data %>% dplyr::select(medical_specialty, transcription) %>% dplyr::filter(stringr::str_detect(transcription, 'steri strips')) %>% dplyr::slice(1)
```

**9** Extract an example of one of the other "top lemmas" by modifying the above code

Answer:-

```{r}
analysis.data %>% dplyr::select(medical_specialty, transcription) %>% dplyr::filter(stringr::str_detect(transcription, 'left ventricular')) %>% dplyr::slice(1)

```



```{r}

lemma.counts <- lemmatized.data %>% dplyr::count(note_id, lemma)
total.counts <- lemma.counts %>% 
                      dplyr::group_by(note_id) %>% 
                      dplyr::summarise(total=sum(n))

all.counts <- dplyr::left_join(lemma.counts, total.counts)

emr.dcm <- all.counts %>% tidytext::cast_dtm(note_id, lemma, n)
```


```{r}
emr.lda <- topicmodels::LDA(emr.dcm, k=5, control=list(seed=42))
emr.topics <- tidytext::tidy(emr.lda, matrix='beta')
```


```{r}

top.terms <- emr.topics %>% dplyr::group_by(topic) %>% 
  dplyr::slice_max(beta, n=10) %>%
  dplyr::ungroup() %>%
  dplyr::arrange(topic, -beta)


top.terms %>% 
  dplyr::mutate(term=tidytext::reorder_within(term, beta, topic)) %>% 
  ggplot2::ggplot(ggplot2::aes(beta, term, fill=factor(topic))) + 
    ggplot2::geom_col(show.legend=FALSE) + 
    ggplot2::facet_wrap(~ topic, scales='free')  +
    ggplot2::theme(axis.text.x = element_text(angle = 45,vjust = 1,hjust = 1)) +
    tidytext::scale_y_reordered()
```





```{r}
specialty_gamma <- tidytext::tidy(emr.lda, matrix='gamma')

# we need to join in the specialty from the note_id
note_id_specialty_mapping <- lemmatized.data %>%
  dplyr::mutate(document=as.character(note_id)) %>% 
  dplyr::select(document, medical_specialty) %>% 
  dplyr::distinct()

specialty_gamma <- dplyr::left_join(specialty_gamma, note_id_specialty_mapping)
```

```{r}

specialty_gamma %>%
  dplyr::mutate(medical_specialty = reorder(medical_specialty, gamma * topic)) %>%
  ggplot2::ggplot(ggplot2::aes(factor(topic), gamma)) +
  ggplot2::geom_boxplot() +
  ggplot2::facet_wrap(~ medical_specialty) +
  ggplot2::labs(x = "topic", y = expression(gamma))
```



**10** Repeat this with a 6 topic LDA, do the top terms from the 5 topic LDA still turn up? How do the specialties get split into sub-topics?

Answer:-
```{r}
lda_6 <- topicmodels::LDA(emr.dcm, k = 6, control = list(seed = 123))

top.terms.6 <- tidytext::tidy(lda_6, matrix = "beta") %>%
  group_by(topic) %>%
  slice_max(order_by = beta, n = 10) %>%
  ungroup()

top.terms.6 %>%
  mutate(term = tidytext::reorder_within(term, beta, topic)) %>%
  ggplot(aes(beta, term, fill = factor(topic))) +
  geom_col(show.legend = FALSE) +
  facet_wrap(~topic, scales = "free") +
  theme(axis.text.x = element_text(angle = 45, hjust = 1)) +
  tidytext::scale_y_reordered()


specialty_gamma6 <- tidytext::tidy(lda_6, matrix='gamma')


note_id_specialty_mapping6 <- lemmatized.data %>%
  dplyr::mutate(document=as.character(note_id)) %>% 
  dplyr::select(document, medical_specialty) %>% 
  dplyr::distinct()

specialty_gamma6 <- dplyr::left_join(specialty_gamma6, note_id_specialty_mapping6)


specialty_gamma6 %>%
  dplyr::mutate(medical_specialty = reorder(medical_specialty, gamma * topic)) %>%
  ggplot2::ggplot(ggplot2::aes(factor(topic), gamma)) +
  ggplot2::geom_boxplot() +
  ggplot2::facet_wrap(~ medical_specialty) +
  ggplot2::labs(x = "topic", y = expression(gamma))

```
When repeated with a 6-topic LDA, several top terms from the 5-topic model (e.g., “prepped draped”, “postoperative diagnosis”, "preoperative diagnosis", “coronary artery”) still appear, indicating semantic stability across models. However, the 6-topic model introduces more granularity in how the notes are grouped. Specifically, surgical-related content now separates into at least two distinct clusters—likely distinguishing between types of procedures. Orthopedic notes also appear more focused. The 6-topic model enables finer sub-topic resolution while maintaining key domain-relevant vocabulary, offering better interpretability for clinical NLP tasks.





## Credits

Examples draw heavily on material (and directly quotes/copies text) from Julia Slige's `tidytext` textbook.

